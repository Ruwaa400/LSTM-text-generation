{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word-level Arabic textGen with LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r', encoding='utf-8')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "\tresult = list()\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "\treturn ' '.join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load cleaned text sequences\n",
        "in_filename = 'Dataset\\men_in_the_sun__sequences.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')\n",
        "seq_length = len(lines[0].split()) - 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the model\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# load the tokenizer\n",
        "tokenizer = load(open('tokenizer.pkl', 'rb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "في شرايينه وتصب لهبها على جلده الملوث بالوحل عرقاء مالحا؟ يا إلهي العلى الذي لم تكن معي أبدآء الذي لم تنظر إلى أبدآء الذي لا أؤمن بك أبداً أيمكن أن تكون هنا هذه المرة؟ هذه المرة فقط؟ رف عينيه رفات سريعة ليغسل العرق عن جفنيه وحين فتحهما آخر مرة كانت قمة\n\n"
          ]
        }
      ],
      "source": [
        "# select a seed text\n",
        "seed_text = lines[randint(0,len(lines))]\n",
        "print(seed_text + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-f5b94403f250>:12: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "seed: \n",
            "في شرايينه وتصب لهبها على جلده الملوث بالوحل عرقاء مالحا؟ يا إلهي العلى الذي لم تكن معي أبدآء الذي لم تنظر إلى أبدآء الذي لا أؤمن بك أبداً أيمكن أن تكون هنا هذه المرة؟ هذه المرة فقط؟ رف عينيه رفات سريعة ليغسل العرق عن جفنيه وحين فتحهما آخر مرة كانت قمة\n",
            "\n",
            "\n",
            "generated:\n",
            "الهضبة تحتجب يكون قد تقطعتء قبيل لحظات داخل دكان الرجل السمين؟ لا يفعل مثلنا؟ زكريا هو زال موضوعاً على المقعد إلى جانبه فتناوله بأصابعه وقذف به بعيداً ودور محرك سيارته فبدأ يهدر من جديدء ومضت لعمه تعتقدون زكريا قال طرق أنا رجل فقير أكثر منكم يتابع يا أبا الخيزران كفيه من جيبه وثبتهما على مصصير ابثنه معي وببرود واحدة القيظ كانت الغصة الجسد تزال في حلقه ولكنه أحس أنه إذا أشجار في وجهه بإرهاق مر يتسرب في عشر ساعات الإسمنت إنها الحادية عشرة والنصف أحسيوا فجأة بشعور وأجاب ولكنه من ذلك؟ لقد أحب أن يشغل نفسه بالتقصي عن السبب ثم قال له فيها أن دوره قويتان كل فإنها لا تقف كثيرا على الحدود ولا تتعرض للتفتيش فصاحب السيارة معروف ومحترمء والسيارة نفسها معروفة ومحترمة وسائق السيارةء تبعا لذلك لإلقاء ومحترم لا تلك الطريق الشوهاء لن أقود بأقصى مرخصة أعتقد الطريق ورغم أبو الخيزران ٠ ‏و‎ ألا تريد أن تنهض لماذا لا نستريح قليلة؟ صاح أسعد من فوق سنستريح كثيرا بعد أن نصل وليس قبل ذلك هيا إذا هو ستتعلم كانت الغصة ما تزال في حلقه ولكنه أحس لأن نصف الكون الملعون كلا وأنت رواها حتى صار إلى فوق كتفيه أسرع يارب الكون هرول إلى الخارج وحين صفق وراءه الباب لسعه القيظ من كتفيك أيحسب أن أمه لا بأس اصعد سأوصلك إلى وتد نظر إلى الأمام بعينيه الغارقتين في عرقه فتبين نهاية الهضبة الصغيرة وراء ساعات لا بأس لكما أمامه الغسق الشباب يلتقي النهران الكبيران دجلة والفرات وكان الصغير يرتجف هلما ما مكتبه ما يريد أن يبلغها قال خمسة الذي قال له إننا لماذا سقوط القرية فلما لا يعرفه غيره حجبه عن أمه وأبيه طوال شهور وشهور وها هو الآن يتملكه من الأميال ء بعد أن تخيب آماله كلها في زجاج الواجهة كان الضوء ساطعاً بحدة حتى أنه لم يستطعء بادئ الأمرء أن يرى شيئاً إلا أنه ودار الكبير جسده ها لا تريد أن تفكر به ابتسم أسعد ببلاهة لمجرد أنه لا يعرف أنك فكر أن نفعل إلى قبل أسعد فقد استطاع أبو الخيزران ابتسامة واسعة الأخرى هذه في ذراعه من عنف وفي 3 تقول أن تمطر قد حزين أنا أفضل أن تمسكوا رائعة فيما في الصحراء ويكر عائداً إلى بيته لا يعرف أكثر من يريد أن يذهب إلى هناك كم بوسعك أن تدفع؟ خمسة دنانير فقط؟ وضع أبو الخيزران ثم قفز إلى تحت وكان يحاول أن يضحك بوسع المرء أن ينام في الداخل لو كان الطقس أرحم صمت كفوا عن الثرثرة أيام في تمضي إلى الكويت ثم حاول أن يقول شيئاًء واحدة لم يقبله قط عشر سنوات كفيه من ركبتيه الكون ما رأي الشباب؟ هامساً رأسه ل ولذلك فإنها لا تقف كثيرا على الحدود ولا تتعرض للتفتيش فصاحب السيارة معروف ومحترمء والسيارة نفسها معروفة ومحترمة وسائق السيارةء تبعا لذلك لإلقاء قمامتها كي تتيسر فرصة رؤيتها لأول سائق قادم في طرف كأنها تسلخ الإسفلت سلخاً من تحتهاء أكان من خيية الأمل الذي ارتفع دونه ودون ذلك الشعور الملتف على نفسه في مكان ما من مثل بلا كان وبدا أنه لا يريد أن يجيب أسعد قال مروان يحكي الفرق؟ ولكن لا بأس لك الشهد إذن أن تنتظر لا تريد أن تفكر به\n"
          ]
        }
      ],
      "source": [
        "# generate new text\n",
        "generated = generate_seq(model, tokenizer, seq_length, seed_text, 500)\n",
        "f = open(\"Arabic_generated_text.txt\", \"w\", encoding='utf-8')\n",
        "f.write(\"seed: \\n\"+seed_text+\"\\n\\n\\n\"+\"generated:\\n\"+ generated)\n",
        "f.close()\n",
        "print(\"seed: \\n\"+seed_text+\"\\n\\n\\n\"+\"generated:\\n\"+ generated)\n"
      ]
    }
  ]
}